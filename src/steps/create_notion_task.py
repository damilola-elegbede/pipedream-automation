"""
Create Notion Task from Email

Creates Notion database entries from email data with AI-powered extraction
of actionable information using Claude.

Usage: Copy-paste into a Pipedream Python step
Required:
  - Connect Notion account with OAuth
  - Set NOTION_DATABASE_ID environment variable in Pipedream
  - Set ANTHROPIC_API_KEY environment variable in Pipedream
"""
import os
import requests
import time
import re
import json
import random

# Import analyze_email - handles both Pipedream (same directory) and test environments
try:
    from analyze_email_with_claude import analyze_email
except ImportError:
    from steps.analyze_email_with_claude import analyze_email

# --- Configuration ---
PREVIOUS_STEP_NAME = "fetch_gmail_emails"
NOTION_API_VERSION = "2022-06-28"
MAX_CODE_BLOCK_LENGTH = 2000


def extract_email(email_string):
    """Extracts the email address from a string potentially containing a name."""
    if not email_string:
        return None
    match = re.search(r'<([^>]+)>', email_string)
    if match:
        return match.group(1)
    if '@' in email_string and '.' in email_string.split('@')[-1]:
        potential_email = email_string.split()[-1]
        if '@' in potential_email:
            return potential_email.strip('<>')
    if '@' in email_string:
        return email_string.strip()
    return None


def retry_with_backoff(request_func, max_retries=5):
    """
    Execute request with exponential backoff for rate limits.

    Handles HTTP 429 (Too Many Requests) and 503 (Service Unavailable) errors
    by waiting and retrying with exponential backoff. Respects Retry-After header.
    """
    for attempt in range(max_retries):
        try:
            response = request_func()
            response.raise_for_status()
            return response
        except requests.HTTPError as e:
            if e.response is not None and e.response.status_code in (429, 503) and attempt < max_retries - 1:
                retry_after = e.response.headers.get('Retry-After')
                if retry_after:
                    try:
                        wait = float(retry_after)
                    except ValueError:
                        wait = (2 ** attempt) + random.uniform(0, 1)
                else:
                    wait = (2 ** attempt) + random.uniform(0, 1)
                print(f"Rate limited. Waiting {wait:.1f}s (attempt {attempt + 1}/{max_retries})")
                time.sleep(wait)
            else:
                raise
    raise Exception(f"Max retries ({max_retries}) exceeded")


def build_notion_properties(email_data, gmail_message_id):
    """Constructs the 'properties' dictionary for the Notion API request.

    Now includes Message ID property to enable duplicate detection.
    """
    properties = {}
    subject = email_data.get("subject", "No Subject")
    properties["Task name"] = {
        "title": [{"type": "text", "text": {"content": subject}}]
    }

    # Store Gmail Message ID for duplicate detection
    properties["Message ID"] = {
        "rich_text": [{"type": "text", "text": {"content": gmail_message_id}}]
    }

    url = email_data.get("url")
    if url:
        properties["Original Email Link"] = {"url": url}
    else:
        print(f"Warning: Missing 'url' for subject: {subject}")

    sender_raw = email_data.get("sender")
    sender_email = extract_email(sender_raw)
    if sender_email:
        properties["Sender"] = {"email": sender_email}
    else:
        print(f"Warning: Could not extract valid email from 'sender' for subject: {subject} (Raw: {sender_raw})")

    receiver_raw = email_data.get("receiver")
    receiver_email = extract_email(receiver_raw.split(',')[0]) if receiver_raw else None
    if receiver_email:
        properties["To"] = {"email": receiver_email}
    else:
        print(f"Warning: Could not extract valid email from 'receiver' for subject: {subject} (Raw: {receiver_raw})")
    return properties


def check_existing_task(headers, database_id, gmail_message_id):
    """Query Notion to check if task already exists for this email.

    Returns the existing page data if found, None otherwise.
    """
    query_url = f"https://api.notion.com/v1/databases/{database_id}/query"
    filter_payload = {
        "filter": {
            "property": "Message ID",
            "rich_text": {"equals": gmail_message_id}
        }
    }
    try:
        response = retry_with_backoff(
            lambda: requests.post(query_url, headers=headers, json=filter_payload, timeout=30)
        )
        results = response.json().get("results", [])
        if results:
            return results[0]
        return None
    except requests.exceptions.HTTPError as e:
        print(f"  Warning: Could not check for existing task: {e}")
        return None
    except Exception as e:
        print(f"  Warning: Error checking for existing task: {e}")
        return None


def build_page_content_blocks(plain_text_body, analysis):
    """
    Constructs a list of Notion block objects from Claude analysis.

    Creates a structured page with:
    - Summary callout
    - Action items (checkboxes)
    - Key dates
    - Important links
    - Key contacts
    - Original email in collapsed toggle

    Args:
        plain_text_body: Original email plain text
        analysis: Dict from analyze_email() or None

    Returns:
        List of Notion block objects
    """
    children_blocks = []

    if analysis:
        # Summary callout
        if analysis.get("summary"):
            urgency_emoji = {"high": "ðŸ”´", "medium": "ðŸŸ¡", "low": "ðŸŸ¢"}.get(
                analysis.get("urgency", "medium"), "ðŸŸ¡"
            )
            children_blocks.append({
                "object": "block",
                "type": "callout",
                "callout": {
                    "rich_text": [{"type": "text", "text": {"content": analysis["summary"]}}],
                    "icon": {"type": "emoji", "emoji": urgency_emoji},
                    "color": "blue_background"
                }
            })

        # Action Items section
        action_items = analysis.get("action_items", [])
        if action_items:
            children_blocks.append({
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "Action Items"}}]
                }
            })
            for item in action_items:
                children_blocks.append({
                    "object": "block",
                    "type": "to_do",
                    "to_do": {
                        "rich_text": [{"type": "text", "text": {"content": item}}],
                        "checked": False
                    }
                })

        # Key Dates section
        key_dates = analysis.get("key_dates", [])
        if key_dates:
            children_blocks.append({
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "Key Dates"}}]
                }
            })
            for date_item in key_dates:
                date_str = date_item.get("date", "")
                context = date_item.get("context", "")
                text = f"{date_str} - {context}" if context else date_str
                children_blocks.append({
                    "object": "block",
                    "type": "bulleted_list_item",
                    "bulleted_list_item": {
                        "rich_text": [{"type": "text", "text": {"content": text}}]
                    }
                })

        # Important Links section
        links = analysis.get("important_links", [])
        if links:
            children_blocks.append({
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "Important Links"}}]
                }
            })
            for link in links:
                url = link.get("url", "")
                description = link.get("description", url)
                if url:
                    children_blocks.append({
                        "object": "block",
                        "type": "bulleted_list_item",
                        "bulleted_list_item": {
                            "rich_text": [{
                                "type": "text",
                                "text": {"content": description, "link": {"url": url}}
                            }]
                        }
                    })

        # Key Contacts section
        contacts = analysis.get("key_contacts", [])
        if contacts:
            children_blocks.append({
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "Key Contacts"}}]
                }
            })
            for contact in contacts:
                name = contact.get("name", "")
                email = contact.get("email", "")
                role = contact.get("role", "")
                parts = []
                if name:
                    parts.append(name)
                if role:
                    parts.append(f"({role})")
                if email:
                    parts.append(f"- {email}")
                text = " ".join(parts) if parts else "Unknown contact"
                children_blocks.append({
                    "object": "block",
                    "type": "bulleted_list_item",
                    "bulleted_list_item": {
                        "rich_text": [{"type": "text", "text": {"content": text}}]
                    }
                })

        # Divider before original email
        children_blocks.append({
            "object": "block",
            "type": "divider",
            "divider": {}
        })

    # Original Email in collapsed toggle
    if plain_text_body and plain_text_body.strip():
        # Build toggle children with chunked code blocks
        toggle_children = []
        start_index = 0
        while start_index < len(plain_text_body):
            chunk = plain_text_body[start_index:start_index + MAX_CODE_BLOCK_LENGTH]
            toggle_children.append({
                "object": "block",
                "type": "code",
                "code": {
                    "rich_text": [{"type": "text", "text": {"content": chunk}}],
                    "language": "plain text"
                }
            })
            start_index += MAX_CODE_BLOCK_LENGTH

        children_blocks.append({
            "object": "block",
            "type": "toggle",
            "toggle": {
                "rich_text": [{"type": "text", "text": {"content": "Original Email"}}],
                "children": toggle_children
            }
        })
    elif not analysis:
        # No analysis AND no plain text - add a note
        children_blocks.append({
            "object": "block",
            "type": "paragraph",
            "paragraph": {
                "rich_text": [{"type": "text", "text": {"content": "No email content available."}}]
            }
        })

    return children_blocks


def handler(pd: "pipedream"):
    # --- 1. Get Notion and Anthropic API Credentials ---
    try:
        notion_token = pd.inputs["notion"]["$auth"]["oauth_access_token"]
    except KeyError:
        raise Exception("Notion account not connected or input name is not 'notion'. Please connect Notion using OAuth.")

    # Get Database ID from environment variable (required)
    database_id = os.environ.get("NOTION_DATABASE_ID")
    if not database_id:
        raise Exception("NOTION_DATABASE_ID environment variable not set. Set it in Pipedream Settings > Environment Variables")

    # Get Anthropic API key for Claude analysis
    anthropic_api_key = os.environ.get("ANTHROPIC_API_KEY")
    if anthropic_api_key:
        print("Using Anthropic API key from environment variables for email analysis.")
    else:
        print("Warning: ANTHROPIC_API_KEY not found in environment. Email analysis will be skipped.")
        print("Set ANTHROPIC_API_KEY in Pipedream Settings > Environment Variables")

    # --- 2. Get Email Data from Previous Step ---
    try:
        emails_to_process = pd.steps[PREVIOUS_STEP_NAME]["$return_value"]
    except KeyError:
        print(f"Error: Could not find return value from step '{PREVIOUS_STEP_NAME}'.")
        return {"error": f"Could not find data from step {PREVIOUS_STEP_NAME}", "successful_mappings": [], "errors": []}
    except Exception as e:
        print(f"An unexpected error occurred accessing previous step data: {e}")
        return {"error": "Failed to access previous step data.", "successful_mappings": [], "errors": []}

    if not emails_to_process:
        print("No email data received. Nothing to process.")
        return {"status": "No data received", "created_items": 0, "successful_mappings": [], "errors": []}
    if not isinstance(emails_to_process, list):
        print(f"Error: Expected a list from step '{PREVIOUS_STEP_NAME}', got {type(emails_to_process)}.")
        return {"error": "Invalid data format from previous step.", "successful_mappings": [], "errors": []}

    # --- 3. Prepare for Notion API Calls ---
    notion_pages_api_url = "https://api.notion.com/v1/pages"
    notion_blocks_api_url_base = "https://api.notion.com/v1/blocks/"
    headers = {
        "Authorization": f"Bearer {notion_token}",
        "Content-Type": "application/json",
        "Notion-Version": NOTION_API_VERSION,
    }

    successful_mappings = []
    errors = []
    skipped_duplicates = 0
    print(f"Starting to process {len(emails_to_process)} email(s) for Notion...")

    # --- 4. Loop Through Emails and Create Notion Items & Content ---
    for index, email_data in enumerate(emails_to_process):
        print(f"\nProcessing email {index + 1}/{len(emails_to_process)} (Subject: {email_data.get('subject', 'N/A')})...")

        if not isinstance(email_data, dict) or "message_id" not in email_data:
            print(f"  Skipping item {index + 1}: Invalid format or missing 'message_id'.")
            errors.append({"index": index + 1, "error": "Invalid item format or missing message_id"})
            continue

        gmail_message_id = email_data["message_id"]
        page_id = None
        email_analysis = None

        # --- Check for existing task (duplicate detection) ---
        existing_task = check_existing_task(headers, database_id, gmail_message_id)
        if existing_task:
            existing_page_id = existing_task.get("id")
            print(f"  Task already exists for message {gmail_message_id} (Page ID: {existing_page_id}). Skipping creation.")
            successful_mappings.append({
                "gmail_message_id": gmail_message_id,
                "notion_page_id": existing_page_id,
                "skipped": True,
                "reason": "duplicate"
            })
            skipped_duplicates += 1
            continue

        try:
            properties_payload = build_notion_properties(email_data, gmail_message_id)
            if "Task name" not in properties_payload:
                raise ValueError("Failed to generate 'Task name' property.")

            page_creation_body = {
                "parent": {"database_id": database_id},
                "properties": properties_payload,
            }
            # Log only Message ID (Task name derived from subject may contain PII)
            safe_props = {"Message ID": properties_payload.get("Message ID")}
            print(f"  Sending request to create Notion page with properties: {json.dumps(safe_props, indent=2)}")
            response_page = retry_with_backoff(
                lambda body=page_creation_body: requests.post(
                    notion_pages_api_url, headers=headers, json=body, timeout=30
                )
            )
            created_page_data = response_page.json()
            page_id = created_page_data.get("id")
            print(f"  Successfully created Notion page: ID {page_id}")

            print(f"    Waiting for 2 seconds before appending content to page {page_id}...")
            time.sleep(2)

            # Analyze email with Claude
            plain_text_content = email_data.get("plain_text_body", "")
            if anthropic_api_key and plain_text_content:
                email_analysis = analyze_email(
                    subject=email_data.get("subject", ""),
                    sender=email_data.get("sender", ""),
                    date=email_data.get("date", ""),
                    body=plain_text_content,
                    anthropic_key=anthropic_api_key
                )
            elif not plain_text_content:
                print("    No plain text body found in email_data for analysis.")

            if page_id:
                content_blocks = build_page_content_blocks(plain_text_content, email_analysis)
                if content_blocks:
                    chunks = [content_blocks[i:i + 100] for i in range(0, len(content_blocks), 100)]
                    for chunk_idx, chunk_data in enumerate(chunks):
                        append_blocks_body = {"children": chunk_data}
                        # Log block types only, not full content (may contain sensitive email data)
                        block_types = [b.get("type", "unknown") for b in chunk_data]
                        print(f"    Appending {len(chunk_data)} blocks (chunk {chunk_idx + 1}/{len(chunks)}): {block_types}")

                        blocks_url = f"{notion_blocks_api_url_base}{page_id}/children"
                        retry_with_backoff(
                            lambda url=blocks_url, body=append_blocks_body: requests.patch(
                                url, headers=headers, json=body, timeout=30
                            )
                        )
                        print(f"    Successfully appended content blocks (chunk {chunk_idx + 1}).")
                        if len(chunks) > 1:
                            time.sleep(0.3)
                else:
                    print("    No content blocks (text or image) to append.")
            else:
                print("    Page ID not available, skipping content append.")

            successful_mappings.append({
                "gmail_message_id": gmail_message_id,
                "notion_page_id": page_id,
                "analysis_complete": email_analysis is not None
            })

        except requests.exceptions.HTTPError as http_err:
            status_code_str = 'N/A'
            error_message = str(http_err)
            error_details = {}
            validation_errors = None

            if http_err.response is not None:
                status_code_str = str(http_err.response.status_code)
                try:
                    if 'application/json' in http_err.response.headers.get('Content-Type', ''):
                        error_details = http_err.response.json()
                        error_message = error_details.get('message', str(http_err))
                        validation_errors = error_details.get('validation_errors')
                    else:
                        error_details = {"raw_response": http_err.response.text}
                        error_message = http_err.response.text if http_err.response.text else str(http_err)
                except json.JSONDecodeError:
                    error_details = {"raw_response": http_err.response.text}
                    error_message = f"Failed to decode JSON response. Raw text: {http_err.response.text}"
                except Exception as e_resp:
                    error_message = f"Error processing HTTPError response: {e_resp}"
                    error_details = {"processing_error": str(e_resp)}

            print(f"  HTTP Error for Gmail ID {gmail_message_id}: {status_code_str} - {error_message}")
            if validation_errors:
                print(f"  Validation Errors: {json.dumps(validation_errors, indent=2)}")
            elif error_details:
                print(f"  Error Details: {json.dumps(error_details, indent=2)}")

            errors.append({
                "index": index + 1, "gmail_message_id": gmail_message_id,
                "subject": email_data.get('subject'), "status_code": status_code_str,
                "error": error_message, "validation_errors": validation_errors, "raw_error_details": error_details,
                "notion_page_id_attempted": page_id
            })
        except Exception as e:
            print(f"  An unexpected error for Gmail ID {gmail_message_id}: {e}")
            errors.append({
                "index": index + 1, "gmail_message_id": gmail_message_id,
                "subject": email_data.get('subject'), "error": f"Unexpected error: {e}",
                "notion_page_id_attempted": page_id
            })
        time.sleep(0.5)

    # --- 5. Return Summary (ALWAYS include successful_mappings) ---
    status = "Completed" if not errors else "Partial"
    print("\n--- Processing Complete ---")
    print(f"Successfully processed items: {len(successful_mappings)}")
    print(f"Skipped duplicates: {skipped_duplicates}")
    print(f"Errors encountered: {len(errors)}")
    return {
        "status": status,
        "total_processed": len(emails_to_process),
        "successful_mappings": successful_mappings,
        "skipped_duplicates": skipped_duplicates,
        "errors": errors
    }
